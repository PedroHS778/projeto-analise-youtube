name: Coleta de Dados do YouTube

# Este 'workflow' roda nos seguintes eventos:
on:
  # 1. Permite rodar manualmente (pelo site do GitHub)
  workflow_dispatch:

  # 2. Agenda para rodar de hora em hora
  schedule:
    - cron: '0 * * * *' # "No minuto 0, a cada hora, todo dia"

jobs:
  build-and-commit:
    runs-on: ubuntu-latest # Usa uma máquina virtual Linux

    steps:
      # 1. Baixa o código do repositório
      - name: Checkout do código
        uses: actions/checkout@v4

      # 2. Configura o Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10' # Usa Python 3.10

      # 3. Instala as bibliotecas do requirements.txt
      - name: Instalar dependências
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # 4. Executa o script coletor.py
      - name: Executar script de coleta
        run: python coletor.py
        env:
          # injeta o "Secret"
          YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}

      # 5. Salva (faz "commit") o banco de dados atualizado
      - name: Fazer commit do banco de dados
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          # Adiciona o arquivo do banco de dados (se ele foi criado ou modificado)
          git add youtube_stats.db || echo "Nenhum banco de dados para adicionar"
          # Verifica se há mudanças e faz o commit
          git diff --staged --quiet || git commit -m "Atualiza banco de dados (coleta automática)"
          # Empurra (push) as mudanças de volta para o repositório
          git push

